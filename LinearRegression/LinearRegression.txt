
Linear regression is a fundamental statistical and machine learning technique used to model the relationship between a dependent variable and one or more independent variables. 
It is widely used for predicting outcomes and understanding the relationships between variables.

Key Concepts:
- Linear Relationship: Assumes a linear relationship between the dependent and independent variables, represented by the equation:
    - Y = b0 + b1.x1 + b2.x2 + ... + bn.xn + e 
        - b0 = intercept
        - b1... bn = coefficients of the independent variables
        - e = error term

Types of Linear Regression:
- Simple Linear Regression: Models the relationship between two variables, one independent and one dependent.
- Multiple Linear Regression: Models the relationship between the dependent variable and two or more independent variables.

Advantages:
- Interpretability: The model provides clear insights into the relationships between variables and how each predictor impacts the dependent variable.
- Efficiency: Computationally efficient and works well with small to medium-sized datasets.
- Foundation for Complex Models: Serves as a basis for more complex models and techniques.

Disadvantages:
- Linearity Assumption: Assumes a linear relationship, which may not capture complex patterns in data.
- Sensitivity to Outliers: Can be significantly affected by outliers, leading to biased predictions.
- Multicollinearity: High correlation between independent variables can affect the stability and interpretation of the coefficients.